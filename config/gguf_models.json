{
  "base_dir": "LLM/GGUF",
  "qwenVL_model": {
    "Qwen3-VL-4B-Instruct-GGUF": {
      "author": "Qwen",
      "repo_name": "Qwen3-VL-4B-Instruct-GGUF",
      "repo_id": "Qwen/Qwen3-VL-4B-Instruct-GGUF",
      "mmproj_file": "mmproj-Qwen3VL-4B-Instruct-F16.gguf",
      "model_files": [
        "Qwen3VL-4B-Instruct-Q4_K_M.gguf",
        "Qwen3VL-4B-Instruct-Q8_0.gguf",
        "Qwen3VL-4B-Instruct-F16.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-8B-Instruct-GGUF": {
      "author": "Qwen",
      "repo_name": "Qwen3-VL-8B-Instruct-GGUF",
      "repo_id": "Qwen/Qwen3-VL-8B-Instruct-GGUF",
      "mmproj_file": "mmproj-Qwen3VL-8B-Instruct-F16.gguf",
      "model_files": [
        "Qwen3VL-8B-Instruct-Q4_K_M.gguf",
        "Qwen3VL-8B-Instruct-Q8_0.gguf",
        "Qwen3VL-8B-Instruct-F16.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-4B-Thinking-GGUF": {
      "author": "Qwen",
      "repo_name": "Qwen3-VL-4B-Thinking-GGUF",
      "repo_id": "Qwen/Qwen3-VL-4B-Thinking-GGUF",
      "mmproj_file": "mmproj-Qwen3VL-4B-Thinking-F16.gguf",
      "model_files": [
        "Qwen3VL-4B-Thinking-Q4_K_M.gguf",
        "Qwen3VL-4B-Thinking-Q8_0.gguf",
        "Qwen3VL-4B-Thinking-F16.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-8B-Thinking-GGUF": {
      "author": "Qwen",
      "repo_name": "Qwen3-VL-8B-Thinking-GGUF",
      "repo_id": "Qwen/Qwen3-VL-8B-Thinking-GGUF",
      "mmproj_file": "mmproj-Qwen3VL-8B-Thinking-F16.gguf",
      "model_files": [
        "Qwen3VL-8B-Thinking-Q4_K_M.gguf",
        "Qwen3VL-8B-Thinking-Q8_0.gguf",
        "Qwen3VL-8B-Thinking-F16.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-2B-Instruct-GGUF": {
      "author": "Qwen",
      "repo_name": "Qwen3-VL-2B-Instruct-GGUF",
      "repo_id": "Qwen/Qwen3-VL-2B-Instruct-GGUF",
      "mmproj_file": "mmproj-Qwen3VL-2B-Instruct-F16.gguf",
      "model_files": [
        "Qwen3VL-2B-Instruct-Q4_K_M.gguf",
        "Qwen3VL-2B-Instruct-Q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-2B-Thinking-GGUF": {
      "author": "Qwen",
      "repo_name": "Qwen3-VL-2B-Thinking-GGUF",
      "repo_id": "Qwen/Qwen3-VL-2B-Thinking-GGUF",
      "mmproj_file": "mmproj-Qwen3VL-2B-Thinking-F16.gguf",
      "model_files": [
        "Qwen3VL-2B-Thinking-Q4_K_M.gguf",
        "Qwen3VL-2B-Thinking-Q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-30B-A3B-Instruct-GGUF": {
      "author": "unsloth",
      "repo_name": "Qwen3-VL-30B-A3B-Instruct-GGUF",
      "repo_id": "unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF",
      "mmproj_file": "mmproj-F16.gguf",
      "model_files": [
        "Qwen3-VL-30B-A3B-Instruct-Q4_K_M.gguf",
        "Qwen3-VL-30B-A3B-Instruct-Q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-30B-A3B-Thinking-GGUF": {
      "author": "unsloth",
      "repo_name": "Qwen3-VL-30B-A3B-Thinking-GGUF",
      "repo_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF",
      "mmproj_file": "mmproj-F16.gguf",
      "model_files": [
        "Qwen3-VL-30B-A3B-Thinking-Q4_K_M.gguf",
        "Qwen3-VL-30B-A3B-Thinking-Q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen3-VL-32B-Thinking-GGUF": {
      "author": "unsloth",
      "repo_name": "Qwen3-VL-32B-Thinking-GGUF",
      "repo_id": "unsloth/Qwen3-VL-32B-Thinking-GGUF",
      "mmproj_file": "mmproj-F16.gguf",
      "model_files": [
        "Qwen3-VL-32B-Thinking-Q4_K_M.gguf",
        "Qwen3-VL-32B-Thinking-Q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen2-VL-2B-Instruct-GGUF": {
      "author": "lmstudio-community",
      "repo_name": "Qwen2-VL-2B-Instruct-GGUF",
      "repo_id": "lmstudio-community/Qwen2-VL-2B-Instruct-GGUF",
      "mmproj_file": "mmproj-model-f32.gguf",
      "model_files": [
        "Qwen2-VL-2B-Instruct-Q4_K_M.gguf",
        "Qwen2-VL-2B-Instruct-Q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen2-VL-7B-Instruct-GGUF": {
      "author": "lmstudio-community",
      "repo_name": "Qwen2-VL-7B-Instruct-GGUF",
      "repo_id": "lmstudio-community/Qwen2-VL-7B-Instruct-GGUF",
      "mmproj_file": "mmproj-model-f32.gguf",
      "model_files": [
        "Qwen2-VL-7B-Instruct-Q4_K_M.gguf",
        "Qwen2-VL-7B-Instruct-Q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen2-VL-72B-Instruct-GGUF": {
      "author": "lmstudio-community",
      "repo_name": "Qwen2-VL-72B-Instruct-GGUF",
      "repo_id": "lmstudio-community/Qwen2-VL-72B-Instruct-GGUF",
      "mmproj_file": "mmproj-model-f32.gguf",
      "model_files": [
        "Qwen2-VL-72B-Instruct-Q4_K_M.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen2.5-VL-3B-Instruct-GGUF": {
      "author": "lmstudio-community",
      "repo_name": "Qwen2.5-VL-3B-Instruct-GGUF",
      "repo_id": "lmstudio-community/Qwen2.5-VL-3B-Instruct-GGUF",
      "mmproj_file": "mmproj-model-f16.gguf",
      "model_files": [
        "Qwen2.5-VL-3B-Instruct-Q4_K_M.gguf",
        "Qwen2.5-VL-3B-Instruct-Q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen2.5-VL-7B-Instruct-GGUF": {
      "author": "lmstudio-community",
      "repo_name": "Qwen2.5-VL-7B-Instruct-GGUF",
      "repo_id": "lmstudio-community/Qwen2.5-VL-7B-Instruct-GGUF",
      "mmproj_file": "mmproj-model-f16.gguf",
      "model_files": [
        "Qwen2.5-VL-7B-Instruct-Q4_K_M.gguf",
        "Qwen2.5-VL-7B-Instruct-Q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen2.5-VL-32B-Instruct-GGUF": {
      "author": "lmstudio-community",
      "repo_name": "Qwen2.5-VL-32B-Instruct-GGUF",
      "repo_id": "lmstudio-community/Qwen2.5-VL-32B-Instruct-GGUF",
      "mmproj_file": "mmproj-model-f16.gguf",
      "model_files": [
        "Qwen2.5-VL-32B-Instruct-Q4_K_M.gguf",
        "Qwen2.5-VL-32B-Instruct-Q8_0.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    },
    "Qwen2.5-VL-72B-Instruct-GGUF": {
      "author": "lmstudio-community",
      "repo_name": "Qwen2.5-VL-72B-Instruct-GGUF",
      "repo_id": "lmstudio-community/Qwen2.5-VL-72B-Instruct-GGUF",
      "mmproj_file": "mmproj-model-f16.gguf",
      "model_files": [
        "Qwen2.5-VL-72B-Instruct-Q4_K_M.gguf"
      ],
      "defaults": {
        "context_length": 8192,
        "image_max_tokens": 4096,
        "n_batch": 512,
        "gpu_layers": -1,
        "top_k": 0,
        "pool_size": 4194304
      }
    }
  }
}
